
# coding: utf-8

# # Lab 2 - Answering Real-World Questions Using Regular Expressions
# 
# 
# ## Due: Thursday, January 25, 2018,  11:59:00pm
# 
# ### Submission instructions
# After completing this homework, you will turn in two files via Canvas ->  Assignments -> Homework 2:
# Your Notebook, named si330-hw2-YOUR_UNIQUE_NAME.ipynb and
# the HTML file, named si330-hw2-YOUR_UNIQUE_NAME.html
# 
# 
# ### Name:  Joshua Walker
# ### Uniqname: joshwalk
# ### People you worked with: I worked by myself.
# 
# 
# ## Objectives
# After completing this homework assignment, you should
# * know how to use basic regular expressions
# * have gained more experience with composite data structures and sorting
# 
# ### Note: Suggestions for going "Above and Beyond" 80% are highlighted throughout this notebook.

# ### Background
# 
# We will be using a larger version of the Enron email dataset that we used in this week's lab. 
# For this assignment, you will be using a sample of 50,000 email messages from a large 
# database of over 600,000 email 
# messages generated by 158 employees of the Enron Corporation and acquired
# by the Federal Energy Regulatory Commission during its investigation after the company's collapse. 
# The Enron scandal, publicized in October 2001, eventually led to the bankruptcy of the 
# Enron Corporation - one of the largest corporate bankruptcy in U.S. history. 
# Using this 50,000 email sample dataset, you will be answering the following three questions:
# 
# ### Questions
# 1. Which two people exchanged the most email?
# 1. What fraction of the emails were replies?
# 1. What are the 20 most common words used in the "Subject" lines?
# 
# #### Note: you can re-use a lot of the code from this week's lab in this homework assignment
# 
# #### Challenge: Above and Beyond
# We have also made available the complete data set (https://umich.box.com/s/9qtl50x33azttgghrr0whij5vjjijtad), which is approximately 1.4GB when uncompressed.  If you're
# up it, you can try running your code against this dataset (but you probably don't want to do your development 
# work with it).  
# 
# 

# ##### The rest of the notebook contains specific steps that you need to follow and complete.  Places where you need to do something are indicated in <font color="magenta">magenta</font>.

# In[137]:

import csv
import re
from collections import defaultdict
# Fix python's limit on csv field length
import sys
maxInt = sys.maxsize
decrement = True

while decrement:
    # decrease the maxInt value by factor 10 
    # as long as the OverflowError occurs.

    decrement = False
    try:
        csv.field_size_limit(maxInt)
    except OverflowError:
        maxInt = int(maxInt/10)
        decrement = True


# ### Load the data
# We recommend you develop your code using the email_sample_5000.csv (from the lab) and then switch to the email_sample_50k.csv file for your final run.  

# In[138]:

email_data_file_name = "email_sample_50k.csv" # remember to change this to email_sample_50k.csv for your final run

email_data = []

# Add code to load the data
# Hint: look at the code from the lab
with open(email_data_file_name, 'r') as f:
    reader = csv.DictReader(f)
    for row in reader:
        email_data.append(row)


# ### About email
# Email messages consist of two parts: the headers and the body.  They are separated by two newline characters (```\n\n```).
# It's helpful to separate the two into a list of tuples: the list has a tuple for each email;  the first 
# element of the tuple is the headers; the second is the body.  Why bother with this?  Because if we don't we might
# accidentally include headers that were included as part of a reply or forward. 

# In[139]:

headers_bodies = [tuple(email['message'].split('\n\n')) for email in email_data]


# In[140]:

# Print the headers for the first email
print(headers_bodies[0][0])


# In[141]:

# Print the body for the first email
print(headers_bodies[0][1])


# ### <font color="magenta">Q1: Which two people exchanged the most email?</font>
# This is mostly a repeat of the final question from this week's lab.
# The main difference is that we're using a bigger data set.  Choose your regular expression for extracting 
# the sender and especially the recipient ids carefully: each email message can be sent to multiple recipients.
# 
# Your output should consist of a single line that contains two email addresses.
# 
# #### Challenge (Above and Beyond)
# Which headers, other than the "To:" header, can contain recipients? Note that each of those headers (including To:) can contain multiple recipients, each separated by a comma.

# In[142]:

to_match = r'\nFrom: (.*.)\nTo: (.*.)' # two groups: first is sender, second is string of recepients

conversation_count = defaultdict(int)
for email in headers_bodies:
    match = re.findall(to_match, email[0])
    if match:
        recepients = match[0][1].split(', ') # this splits up the recepients when there's multiple
        for recepient in recepients:
            if recepient:
                exchange = [match[0][0], recepient] # creates lists for sender and each recepient
                exchange_sorted = tuple(sorted(exchange))
                conversation_count[exchange_sorted] += 1
        
print(sorted(conversation_count.items(), key= lambda x:x[1], reverse=True)[0][0])


# ### <font color="magenta">Q2: What fraction of the email messages were replies?</font>
# In email messages, replies are typically indicated with a "Subject" header that starts
# with "Re:".  So to answer this question you'll need to find number of email messages
# whose "Subject" header contains "Re: " and then represent that number as a fraction of
# the total number of email messages (i.e. divide the number of replies by the total number of messages).
# 
# ##### Your output should show the fraction as a percentage with no decimal values and should look like:
# ```65% of the email messages were replies.``` (of course with the correct value)
# 
# __Hint__: This is similar to extracting tbe sender email address, except all we want to do is
# determine whether the Subject header contains "Re: ".  We don't care about the rest of the header.
# 
# __Hint__: Try using the .format() function to make your life easier when you're generating your output.
# 
# #### Challenge (Above and Beyond)
# Can you do this in 4 lines of code? 

# In[143]:

# The following line of code makes a list that contains the matching string from each email; the empty matches
# are not included, so that the length of this list gives the count of emails that are replies
# Please note this was done in 3 lines and could have been done in just 1 long line
replies_count = len([x for x in [re.findall(r'Subject: Re:.+', email[0], re.IGNORECASE) for email in headers_bodies] if x])
reply_percentage = str(int(replies_count/len(headers_bodies)*100))
print(reply_percentage + "% of the email messages were replies.")

        


# ### <font color="magenta">Q3: What are the 20 most common words used in the "Subject" lines?

# This is a bit more complex than the previous question.  In this case, we're actually interested in the
# contents of the "Subject:" header.  In addition, we want to exclude strings that indicate the message is
# a reply ("Re:") or a forward ("Fwd:").  Finally, we want to exclude strings that represent commonly used
# "stopwords": words like "a", "an", "and", etc.

# To make it a bit easier for you, we've generated a list of stopwords (we'll learn more about this next week):

# In[144]:

stopWords = {'then', 'was', 'over', 'such', 'him', 'shan', 'at', 'haven', 'as', 'off', 'all', 'of', 'are', 'in', 'm', 'out', 'into', 'too', 'didn', 'wasn', "weren't", 'through', "mightn't", 'below', 'on', 'will', 'there', 'needn', 'wouldn', 'why', 'have', 'yourself', "needn't", 'having', 'am', "it's", 'by', 'itself', 'they', 'he', 'being', 'hadn', 'mustn', 'don', "she's", 'where', 'yours', 'its', 'nor', 'not', 'that', 'the', 'who', 'our', 'these', 'up', 'their', 'himself', 'a', 'about', "don't", 'has', 're', 'to', 'more', 'doesn', 'both', 'which', 'any', 'ain', 'ourselves', 'had', 'this', 'while', 'herself', 'against', 'very', 'weren', 'myself', 'been', "should've", 'what', 'can', 'or', 'your', "isn't", "wasn't", 'does', 'how', "you'll", 'she', "hasn't", "shouldn't", 'my', 'once', 's', "hadn't", 'those', 'is', 'do', 'ours', 'but', "wouldn't", 'his', 'now', 'down', 'each', 'i', 'here', 'from', 'me', 'other', 'be', 'hers', "you're", 'until', 'further', 'y', 'own', 'again', 'just', "haven't", "shan't", 'under', 'when', "doesn't", 'and', "won't", 'no', 'above', 'them', 've', 'so', 'if', 'we', 'were', 'same', 'with', 'mightn', 'ma', 'for', 'hasn', 'couldn', 'after', 'aren', 'yourselves', "you'd", 'should', "aren't", 'o', "didn't", 'themselves', 'most', 'whom', 'shouldn', 'you', 'between', "couldn't", "you've", 'an', 'because', 'before', "mustn't", 'won', 'only', 'doing', 'some', 'her', 'did', 't', 'during', 'it', 'll', 'isn', "that'll", 'd', 'theirs', 'few', 'than', '-', '&', 'fw:', "re:", '--'}


# The general approach that you should use is to iterate through the headers_bodies list and extracting the
# contents of the Subject: header (excluding Re: and Fwd:).  Then, assuming you have the contents in a string,
# split the string (using the ```.split()``` function). You should convert each of the resulting words to lowercase
# and count the occurences of each one that isn't a stopword.  We've done that a lot using ```defaultdict(int)```.
# 
# Here's some code to get you started.  It assumes you're in the middle of looping though the headers and bodies
# list.  
# ```
# subject = re.search(...) # we're not going to tell you how to do this :)
# lower_subject = subject.lower()
# words = lower_subject.split()
# for word in words:
#     if word not in stopWords:
#         # do something with this word
# ```

# In[152]:

words_dict = defaultdict(int)
for email in headers_bodies:  
    subject = re.findall(r'Subject: (?:Re: )*(?:Fwd: )*(.+.)', email[0], re.IGNORECASE)
    if subject:
        lower_subject = subject[0].lower()
        words = lower_subject.split()
        for word in words:
            if word not in stopWords:
                words_dict[word] += 1


# #### Print the 20 most commonly used words

# In[153]:

# note: added some additional stop words so only words/years result
most_common = sorted(words_dict.items(), key = lambda x:x[1], reverse=True)
for i in range(20):
    print(most_common[i][0])


# In[ ]:



